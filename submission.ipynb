{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso,ElasticNet\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"algoparams_from_ui.json.rtf\",'r') as file:\n",
    "    f=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install striprtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from striprtf.striprtf import rtf_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = rtf_to_text(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object=json.loads(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Read the target and type of regression to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_type': 'Regression',\n",
       " 'target': 'petal_width',\n",
       " 'type': 'regression',\n",
       " 'partitioning': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_object['design_state_data']['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length\n",
      "{'feature_name': 'sepal_length', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values', 'impute_value': 0}}\n",
      "sepal_width\n",
      "{'feature_name': 'sepal_width', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'custom', 'impute_value': -1}}\n",
      "petal_length\n",
      "{'feature_name': 'petal_length', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values', 'impute_value': 0}}\n",
      "petal_width\n",
      "{'feature_name': 'petal_width', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'custom', 'impute_value': -2}}\n",
      "species\n",
      "{'feature_name': 'species', 'is_selected': True, 'feature_variable_type': 'text', 'feature_details': {'text_handling': 'Tokenize and hash', 'hash_columns': 0}}\n"
     ]
    }
   ],
   "source": [
    "for features,values in json_object['design_state_data']['feature_handling'].items():\n",
    "    print(features)\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Read the features (which are column names in the csv) and figure out what missing imputation needs to be applied and apply that to the columns loaded in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(Data,feature,feature_variable_type,feature_details):\n",
    "    if feature_variable_type==\"numerical\":\n",
    "        if feature_details['impute_with']=='Average of values':\n",
    "            Data[feature].fillna(feature_details['impute_value'],inplace=True)\n",
    "        if feature_details['impute_with']=='custom':\n",
    "            Data[feature].fillna(feature_details['impute_value'],inplace=True)\n",
    "    return Data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_handling(json_object,data):\n",
    "    for feature,values in json_object['design_state_data']['feature_handling'].items():\n",
    "        Data=data\n",
    "        if values['is_selected']==True:\n",
    "            data=impute(Data,feature,values['feature_variable_type'],values['feature_details'])  \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "150           1.2          NaN           NaN          NaN  Iris-virginica\n",
       "\n",
       "[151 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=feature_handling(json_object,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-2]\n",
    "y=df[json_object['design_state_data']['target']['target']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length\n",
       "15            5.7          4.4           1.5\n",
       "125           7.2          3.2           6.0\n",
       "11            4.8          3.4           1.6\n",
       "127           6.1          3.0           4.9\n",
       "51            6.4          3.2           4.5\n",
       "..            ...          ...           ...\n",
       "71            6.1          2.8           4.0\n",
       "106           4.9          2.5           4.5\n",
       "14            5.8          4.0           1.2\n",
       "92            5.8          2.6           4.0\n",
       "102           7.1          3.0           5.9\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     0.4\n",
       "125    1.8\n",
       "11     0.2\n",
       "127    1.8\n",
       "51     1.5\n",
       "      ... \n",
       "71     1.3\n",
       "106    1.7\n",
       "14     0.2\n",
       "92     1.2\n",
       "102    2.1\n",
       "Name: petal_width, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Compute feature reduction based on input. See the screenshot below where there can be No Reduction, Corr with Target, Tree-based, PCA. Please make sure you write code so that all options can work. If we rerun your code with a different Json it should work if we switch No Reduction to say PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_reduction(json_object,x,y):\n",
    "    dict_reduction=json_object['design_state_data']['feature_reduction']\n",
    "    if dict_reduction['No_reduction']['is_selected']==True:\n",
    "        x=x\n",
    "        \n",
    "        \n",
    "    if dict_reduction['correlation_with_target']['is_selected']==True:\n",
    "        print(x)#write the code here\n",
    "        \n",
    "    \n",
    "    if dict_reduction['Tree-based']['is_selected']==True:\n",
    "        clf=RandomForestClassifier(n_estimators=4)\n",
    "        clf = clf.fit(x, y)\n",
    "        model = SelectFromModel(clf, prefit=True)\n",
    "        x= model.transform(x)\n",
    "   \n",
    "    if dict_reduction['Principal Component Analysis']['is_selected']==True:\n",
    "        pca=PCA(n_components=dict_1['Principal Component Analysis']['num_of_features_to_keep'])\n",
    "        pca.fit(X_features)\n",
    "        x = pca.transform(x)\n",
    "    \n",
    "    return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "RandomForestRegressor\n",
      "GBTClassifier\n",
      "GBTRegressor\n",
      "LinearRegression\n",
      "LogisticRegression\n",
      "RidgeRegression\n",
      "LassoRegression\n",
      "ElasticNetRegression\n",
      "xg_boost\n",
      "DecisionTreeRegressor\n",
      "DecisionTreeClassifier\n",
      "SVM\n",
      "SGD\n",
      "KNN\n",
      "extra_random_trees\n",
      "neural_network\n"
     ]
    }
   ],
   "source": [
    "dict_model=json_object['design_state_data']['algorithms']\n",
    "for i in dict_model:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Parse the Json and make the model objects (using sklean) that can handle what is required in the “prediction_type” specified in the JSON (See #1 where “prediction_type” is specified). Keep in mind not to pick models that don’t apply for the prediction_type specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(json_object,cv,x,y):\n",
    "    dict_model=json_object['design_state_data']['algorithms']\n",
    "    if json_object['design_state_data']['target']['prediction_type']=='Regression':\n",
    "        if dict_model['RandomForestRegressor']['is_selected']:\n",
    "            model=RandomForestRegressor()\n",
    "            param_RF = {'n_estimators': [10, 20, 30],  # Number of trees in the forest\n",
    "                         'max_depth': [20, 25, 30],    # Maximum depth of the trees\n",
    "                         'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "                         'min_samples_leaf': [5, 10, 20],  # Minimum number of samples required to be at a leaf node\n",
    "                         'bootstrap': [True, False]  # Whether bootstrap samples are used \n",
    "                       }\n",
    "            best_parameter,best_model=model_fit(model,param_RF,cv,x,y)\n",
    "            \n",
    "        \n",
    "        if dict_model['LinearRegression']['is_selected']:\n",
    "            model=LinearRegression()\n",
    "            param_linear = {'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
    "                            'normalize': [True, False],  # Whether to normalize the regressors before fitting\n",
    "                            'copy_X': [True, False],  # Whether to copy the data (if False, may overwrite data)\n",
    "                           }\n",
    "            best_parameter,best_model=model_fit(model,param_linear,cv,x,y)\n",
    "           \n",
    "            \n",
    "            \n",
    "        if dict_model['GBTRegressor']['is_selected']:\n",
    "            model=GradientBoostingRegressor()\n",
    "            param_GBT= {'n_estimators': [67, 89],  # Number of boosting stages\n",
    "                        'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
    "                        'loss': ['ls', 'lad', 'huber', 'quantile'],  # Loss function\n",
    "                        'subsample': [1.0, 0.9, 0.8],  # Fraction of samples used for fitting the trees\n",
    "                        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "                        'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "                        'max_depth': [5, 7, 10]  # Maximum depth of the individual trees\n",
    "                       }\n",
    "            best_parameter,best_model=model_fit(model,param_GBT,cv,x,y)\n",
    "            \n",
    "           \n",
    "            \n",
    "        \n",
    "        if dict_model['RidgeRegression']['is_selected']:\n",
    "            model=Ridge()\n",
    "            param_ridge = {'alpha': [0.1, 0.5, 1.0, 2.0],  # Regularization strength (alpha)\n",
    "                           'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
    "                           'normalize': [True, False],  # Whether to normalize the regressors before fitting\n",
    "                           'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solver for optimization\n",
    "                           'max_iter': [10, 30, 50],  # Maximum number of iterations\n",
    "                           }\n",
    "            best_parameter,best_model=model_fit(model,param_Ridge,cv,x,y)\n",
    "        \n",
    "        if dict_model['LassoRegression']['is_selected']:\n",
    "            model= Lasso()\n",
    "            param_Lasso = {'alpha': [0.1, 0.5, 1.0, 2.0],  # Regularization strength (alpha)\n",
    "                           'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
    "                           'normalize': [True, False],  # Whether to normalize the regressors before fitting\n",
    "                           'max_iter': [10, 30, 50],  # Maximum number of iterations\n",
    "                           }\n",
    "            best_parameter,best_model=model_fit(model,param_Lasso,cv,x,y)\n",
    "            \n",
    "            \n",
    "        if dict_model['ElasticNetRegression']['is_selected']:\n",
    "            model=ElasticNet()\n",
    "            param_Elastic = {'alpha': [0.1, 0.5, 1.0, 2.0],  # Regularization strength (alpha)\n",
    "                             'l1_ratio': [0.1, 0.5, 0.7, 0.9],  # Mixing parameter for L1 and L2 penalties\n",
    "                             'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
    "                             'normalize': [True, False],  # Whether to normalize the regressors before fitting\n",
    "                             'max_iter': [10, 30, 50],  # Maximum number of iterations\n",
    "                             }\n",
    "            best_parameter,best_model=model_fit(model,param_Elastic,cv,x,y)\n",
    "            \n",
    "        \n",
    "        if dict_model['DecisionTreeRegressor']['is_selected']:\n",
    "            model = DecisionTreeRegressor()\n",
    "            param_DT = {'max_depth': [4, 5, 6, 7],  # Maximum depth of the tree\n",
    "                        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "                        'min_samples_leaf': [12, 6],  # Minimum number of samples required to be at a leaf node\n",
    "                        'criterion': ['mse'],  # Splitting criterion (Mean Squared Error)\n",
    "                        'splitter': ['best', 'random'],  # Strategy to choose the split at each node\n",
    "                        }\n",
    "            best_parameter,best_model=model_fit(model,param_DT,cv,x,y)\n",
    "        \n",
    "        if dict_model['SVM']['is_selected']:\n",
    "            model = SVR()\n",
    "            param_SVR = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernels to consider\n",
    "                         'C': [566, 79],  # Regularization parameter (C)\n",
    "                         'gamma': ['scale', 'auto'],  # Kernel coefficient (gamma)\n",
    "                         'tol': [7],  # Tolerance for stopping criterion\n",
    "                         'max_iter': [7]  # Maximum number of iterations for solver\n",
    "                         }\n",
    "            best_parameter,best_model=model_fit(model,param_SVR,cv,x,y)\n",
    "        \n",
    "        if dict_model['KNN']['is_selected']:\n",
    "            model = KNeighborsRegressor()\n",
    "            param_knn = {'n_neighbors': [25,50,75,100],  # Number of neighbors to use\n",
    "                         'weights': ['distance'],  # Weighting method for neighbors (distance-based)\n",
    "                         'algorithm': ['auto'],  # Algorithm used to compute nearest neighbors\n",
    "                         'p': [2],  # Power parameter for Minkowski distance (Euclidean distance)\n",
    "                        }\n",
    "            best_parameter,best_model=model_fit(model,param_SVR,cv,x,y)\n",
    "        #if dict_model['neural_network']['is_selected']:\n",
    "            #model = MLPRegressor()\n",
    "            \n",
    "    return  best_parameter,best_model        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Run the fit and predict on each model – keep in mind that you need to do hyper parameter tuning i.e., use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model,param,cv,x,y):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(x,y)\n",
    "    best_parameter = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_parameter,best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=6\n",
    "cv =TimeSeriesSplit(n_splits=num_folds)\n",
    "_,best_model=model(json_object,cv,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(best_model,x_test):\n",
    "    y_pred = best_model.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_predict(best_model,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Log to the console the standard model metrics that apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metric(y_pred,y_test):\n",
    "    MSE=mean_squared_error(y_test,y_pred)\n",
    "    MAE=mean_absolute_error(y_test,y_pred)\n",
    "    \n",
    "    return MSE,MAE,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE,MAE,r2_score=performance_metric(y_pred,y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error 0.04942055410686957\n",
      "Mean_absolute_error 0.16715074229905563\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean_squared_error\",MSE)\n",
    "print(\"Mean_absolute_error\",MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
